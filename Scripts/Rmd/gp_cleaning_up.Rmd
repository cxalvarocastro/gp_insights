---
title: "Grupo Posadas: General cleaning"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

```{r setup, include=FALSE}
library(dplyr)
library(caret)
library(DT)

setwd("C:/Users/alvar/OneDrive/Escritorio/")

```





```{r data loading, include=FALSE}
#we read de data set
df <- read.csv("C:/Users/alvar/OneDrive/Escritorio/GP/Bases/gp_export_insights.csv",
              sep = "|", 
              encoding = "UTF-8",
              na.strings = c(""," "))

#We join the sub brands to general brands
df <- df %>%
 mutate(brand_gral = case_when(gp_marca_insights %in% c("EXPLOREAN") ~ "EXPLOREAN",
                               gp_marca_insights %in% c("FA CIUDAD","FA PLAYA") ~ "FA",
                               gp_marca_insights %in% c("FIESTA INN","FIESTA INN LOFT") ~ "FIESTA INN",
                               gp_marca_insights %in% c("GAMMA FA") ~ "GAMMA FA",
                               gp_marca_insights %in% c("GRAND FA CIUDAD","GRAND FA PLAYA") ~ "GRAND FA",
                               gp_marca_insights %in% c("LIVE AQUA","LIVE AQUA CIUDAD","LIVE AQUA PLAYA") ~ "LIVE AQUA",
                               gp_marca_insights %in% c("ONE") ~ "ONE"))
```

Table to identify representative brands:

```{r representative brands, include=T, echo=T}


df_count <- df %>%
 group_by(brand_gral,gp_marca_insights) %>%
 summarise(count = n()) %>%
 mutate(pc= round(count*100/sum(count),2))
```


```{r representative brands DT , include=T, echo=F}

DT::datatable(df_count,options = list(
  pageLength = 8,
  lengthMenu = c(8, 16)
)) 
```

```{r droping brands, include=F}
#Drop the records with brand in "FIESTA INN LOFT","LIVE AQUA"
df <- df %>% filter(!gp_marca_insights %in% c("FIESTA INN LOFT","LIVE AQUA"))

```

```{r Drop >30 percent NAs rows, include=F}

#we separate the numeric and categorical variables
var_enum <- df[,c(146,9,15:26,33,35,105:121,125:136)]
var_cate <- df[,c(146,27:32,34,36:104,138:139)]

var_index_enum <- as.character()
for(i in 2:length(colnames(var_enum))){

  l_all <- length(var_enum[,1])
  l_na <- length(which(is.na(var_enum[,i])))

    if(l_na/l_all<=.3){
      var_index_enum <- append(var_index_enum,i)
      
    }

}

var_index_cate <- as.character()
for(i in 2:length(colnames(var_cate))){
  
  l_all <- length(var_cate[,1])
  l_na <- length(which(is.na(var_cate[,i])))
  
  if(l_na/l_all<=.3){
    var_index_cate <- append(var_index_cate,i)
    
  }
  
}

#we drop the rows with more than 30% NA's
df_var_enum <- var_enum[,as.numeric(c(1,var_index_enum))]
df_var_cate <- var_cate[,as.numeric(c(1,var_index_cate))]
```

Once we drop the non representative brands we just keep the variables with at least 70% of non NAs values.

```{r summary 30 percent NAs rows, include=T, echo=F}
summary(df_var_enum)


```

```{r (For Enum) Drop String rows ,include=F, echo=F}
#as we can see the variable gp_conexion_internet has "No lo usé" (did not use it) values
#we will remove the records with this value
df_var_enum <- df_var_enum %>% 
              filter(gp_conexion_internet != "No lo usé") 

#we convert this last variable to numeric
df_var_enum$gp_conexion_internet <- as.numeric(as.character(df_var_enum$gp_conexion_internet))
```

We use the median to impute the NAs values:

```{r replace with Median,include=T, echo=T}
#lets replace the NAs with the median for numeric variables
df_inpute_enum <- preProcess(df_var_enum[,-1], method = "medianImpute")
df_var_enum_fxd <- predict(df_inpute_enum,df_var_enum)
```

```{r summary replace with Median,include=T, echo=T}
summary(df_var_enum_fxd)
```


```{r (For Categorical) Replace with 0 and 1,include=F, echo=F}
#we change Sí & Male to 1 and No & Female to 0
df_var_cate[,-1] <-lapply(df_var_cate[,-1], function(col){
                                            ifelse(col %in% c("Sí","Male"),
                                                   1,
                                                   ifelse(col %in% c("No","Female"),0,col) )
                                                          } 
                          )

#lets replace the NAs with the median 
df_inpute_cate <- preProcess(df_var_cate[,-1], method = "medianImpute")
df_var_cate_fxd <- predict(df_inpute_cate,df_var_cate)

#unif_01 <- round(runif(length(df_var_cate$surveyid),0,1))
#NA2Runif<- function(x){ replace(x, is.na(x), unif_01) }
#df_var_cate_fxd <- replace(df_var_cate[,-1], TRUE, lapply(df_var_cate[,-1], NA2Runif))
```

We do the same with categorical variables transforming Yes to 1 and No to 0

```{r summary (For Categorical) Replace with 0 and 1,include=T, echo=T}
summary(df_var_cate_fxd)
```

```{r Join categ and enum, correlation and standarize,include=F, echo=F}

#we make an inner join to have numeric and categorical variables in the same df
df_cleaned <- merge(df_var_enum_fxd,df_var_cate_fxd,by = "surveyid")
df_cleaned <- df_cleaned[,c(1,3,5,2,4,6:28)]


#Lets split the cleaned df into targets df & predictors df
df_targets <- df_cleaned[,2:3]
df_predictors<- df_cleaned[,4:28]
```

Then we look at the correlation between our predictors:

```{r correlation ,include=T, echo=T}
#we look at the correlation between the predictors
correlation <- cor(df_predictors) 
summary(correlation[upper.tri(correlation)])
```

We drop the variables correlated in more than 0.7

```{r correlation 2 ,include=T, echo=T}
#we remove the variables correlated more than .7
highlyCor <- findCorrelation(correlation, cutoff = .7)
df_predictors_filtered <- df_predictors[,-highlyCor]

corr2 <- cor(df_predictors_filtered)
summary(corr2[upper.tri(corr2)])
```

Finally we sacale the variables to be comparable in the model.

```{r correlation center, scale,include=T, echo=T}
#lets scale all the predictors because the 0 & 1 values and the 0 to 10 ones
#we will make the model using the scaled and non scaled predictors
preProcValues <- preProcess(df_predictors_filtered, method = c("center", "scale"))
df_transformed <- predict(preProcValues, df_predictors_filtered)

summary(df_transformed)

```

